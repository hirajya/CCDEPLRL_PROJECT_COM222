{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fcf38f5",
   "metadata": {},
   "source": [
    "# Bruise Detection using CNN\n",
    "\n",
    "This notebook implements a basic CNN architecture for detecting bruises and other wound types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9af8cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models\n",
    "import os\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb498ab",
   "metadata": {},
   "source": [
    "## Data Loading and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99dae24b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_dir='dataset/Wound_dataset copy', img_size=(224, 224)):\n",
    "    images = []\n",
    "    labels = []\n",
    "    label_to_index = {}\n",
    "    \n",
    "    # Get all class folders\n",
    "    class_folders = [f for f in os.listdir(data_dir) if os.path.isdir(os.path.join(data_dir, f))]\n",
    "    \n",
    "    # Create label mapping\n",
    "    for i, class_name in enumerate(sorted(class_folders)):\n",
    "        label_to_index[class_name] = i\n",
    "    \n",
    "    # Load images and labels\n",
    "    for class_name in class_folders:\n",
    "        class_path = os.path.join(data_dir, class_name)\n",
    "        label_idx = label_to_index[class_name]\n",
    "        \n",
    "        for img_name in os.listdir(class_path):\n",
    "            if img_name.lower().endswith(('.jpg', '.jpeg', '.png')):\n",
    "                img_path = os.path.join(class_path, img_name)\n",
    "                try:\n",
    "                    # Load and preprocess image\n",
    "                    img = Image.open(img_path)\n",
    "                    img = img.convert('RGB')  # Ensure RGB format\n",
    "                    img = img.resize(img_size)\n",
    "                    img_array = np.array(img) / 255.0  # Normalize\n",
    "                    \n",
    "                    images.append(img_array)\n",
    "                    labels.append(label_idx)\n",
    "                except Exception as e:\n",
    "                    print(f\"Error loading {img_path}: {e}\")\n",
    "    \n",
    "    return np.array(images), np.array(labels), label_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59bf681",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "X, y, class_mapping = load_data()\n",
    "print(\"Dataset shape:\", X.shape)\n",
    "print(\"Number of classes:\", len(class_mapping))\n",
    "print(\"\\nClass mapping:\")\n",
    "for class_name, idx in class_mapping.items():\n",
    "    print(f\"{class_name}: {idx}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "351d4962",
   "metadata": {},
   "source": [
    "## Create and Train the CNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "667a0670",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(input_shape, num_classes):\n",
    "    model = models.Sequential([\n",
    "        # Input layer\n",
    "        layers.Input(shape=input_shape),\n",
    "        \n",
    "        # First Convolutional Block\n",
    "        layers.Conv2D(32, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        # Second Convolutional Block\n",
    "        layers.Conv2D(64, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        # Third Convolutional Block\n",
    "        layers.Conv2D(128, (3, 3), activation='relu'),\n",
    "        layers.MaxPooling2D((2, 2)),\n",
    "        layers.BatchNormalization(),\n",
    "        \n",
    "        # Flatten layer\n",
    "        layers.Flatten(),\n",
    "        \n",
    "        # Dense layers\n",
    "        layers.Dense(128, activation='relu'),\n",
    "        layers.Dropout(0.5),\n",
    "        layers.Dense(64, activation='relu'),\n",
    "        layers.Dropout(0.3),\n",
    "        layers.Dense(num_classes, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b558a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Create the model\n",
    "input_shape = X_train[0].shape\n",
    "num_classes = len(class_mapping)\n",
    "model = create_model(input_shape, num_classes)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc559ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=20,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test),\n",
    "    callbacks=[\n",
    "        tf.keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True),\n",
    "        tf.keras.callbacks.ReduceLROnPlateau(factor=0.2, patience=3)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d316979d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training history\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "# Plot accuracy\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "# Plot loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9deda4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"\\nTest accuracy: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b78e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "model.save('models/bruise_detection_model.h5')\n",
    "print(\"Model saved successfully!\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
